{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A First Look at the OpenDP Library\n",
    "\n",
    "Differential Privacy (DP) is a technique used to release information about a population\n",
    "in a way that limits the exposure of any one individual's personal information.\n",
    "This notebook uses the OpenDP Library to demonstrate the basic concepts of DP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opendp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convention for accessing components in OpenDP is via the following import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendp.prelude as dp\n",
    "\n",
    "# we are also using library features that are marked \"contrib\":\n",
    "dp.enable_features(\"contrib\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps of a DP Analysis\n",
    "\n",
    "A differentially private analysis in OpenDP breaks down to the following steps:\n",
    "\n",
    "1. Identify the unit of privacy\n",
    "2. Set privacy loss parameters\n",
    "3. Collect public information\n",
    "4. Mediate access to data\n",
    "5. Submit DP queries\n",
    "\n",
    "We'll illustrate these steps by doing a differentially-private analysis on a teacher survey (a tabular dataset).\n",
    "The raw data consists of survey responses from teachers in primary and secondary schools in an unspecified U.S. state."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Identify the Unit of Privacy\n",
    "The first step in a differentially private analysis is to determine what you are protecting: the unit of privacy.\n",
    "\n",
    "Releases on the teacher survey should conceal the addition or removal of any one teacher's data, \n",
    "and each teacher contributes at most one row to the dataset, \n",
    "so the unit of privacy corresponds to one row contribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "privacy_unit = dp.unit_of(contributions=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadly speaking, differential privacy can be applied to any medium of data for which you can define a unit of privacy.\n",
    "In other contexts, the unit of privacy may correspond to multiple rows, a user ID, or nodes or edges in a graph.\n",
    "\n",
    "The unit of privacy may also be more general or more precise than a single individual.\n",
    "* _more general_: unit of privacy is an entire household, or a company\n",
    "* _more precise_: unit of privacy is a person-month, or device\n",
    "\n",
    "It is highly recommended to choose a unit of privacy that is at least as general as an individual."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Set Privacy Loss Parameters\n",
    "Next, you should determine what level of privacy protection to provide to your units of privacy. \n",
    "This choice may be governed by a variety of factors,\n",
    "such as the amount of harm that individuals could experience if their data were revealed, \n",
    "and your ethical and legal obligations as a data custodian.\n",
    "\n",
    "The level of privacy afforded to units of privacy in a data set is quantified by _privacy loss parameters_.\n",
    "Under _pure_ differential privacy, there is a single privacy-loss parameter, typically denoted epsilon ($\\epsilon$).\n",
    "Epsilon is a non-negative number, where larger values afford less privacy.\n",
    "$\\epsilon$ can be viewed as a proxy for the worst-case risk to a unit of privacy.\n",
    "It is customary to refer to a data release with such bounded risk as epsilon-differentially private ($\\epsilon$-DP).\n",
    "\n",
    "A common rule-of-thumb is to limit $\\epsilon$ to 1.0,\n",
    "but this limit will vary depending on the considerations mentioned above. See ([Hsu et. al](https://arxiv.org/abs/1402.3329)) for a more elaborate discussion on setting epsilon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "privacy_loss = dp.loss_of(epsilon=1.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Collect Public Information\n",
    "The next step is to identify public information about the dataset.\n",
    "\n",
    "* information that is invariant across all potential input datasets (may include column names and per-column categories)\n",
    "* information that is publicly available from other sources\n",
    "* information from other DP releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\n",
    "    \"name\", \"sex\", \"age\", \"maritalStatus\", \"hasChildren\", \"highestEducationLevel\", \n",
    "    \"sourceOfStress\", \"smoker\", \"optimism\", \"lifeSatisfaction\", \"selfEsteem\"\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case (and in most cases), we consider column names public/invariant to the data because they weren't picked in response to the data, they were \"fixed\" before collecting the data.\n",
    "\n",
    "A data invariant is information about your dataset that you are explicitly choosing not to protect,\n",
    "typically under the basis that it is already public or that it does not contain sensitive information ([Abowd et. al](https://arxiv.org/abs/2204.08986)).\n",
    "Be careful because, if an invariant does, indeed, contain sensitive information,\n",
    "then you risk violating the privacy of individuals in your data set.\n",
    "\n",
    "On the other hand, using public information significantly improves the utility of your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Mediate Access to Data\n",
    "At this point, you ideally still haven't looked at the sensitive dataset.\n",
    "This is the first and only point where we access the sensitive dataset in this process.\n",
    "To ensure that your specified differential privacy protections are maintained, \n",
    "the OpenDP Library should mediate all access to the sensitive dataset.\n",
    "This mediation is done via the Context API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "data_url = \"https://raw.githubusercontent.com/opendp/opendp/sydney/teacher_survey.csv\"\n",
    "with urllib.request.urlopen(data_url) as data_req:\n",
    "    data = data_req.read().decode('utf-8')\n",
    "\n",
    "\n",
    "context = dp.Context.compositor(\n",
    "    data=data,\n",
    "    privacy_unit=privacy_unit,\n",
    "    privacy_loss=privacy_loss,\n",
    "    split_evenly_over=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the privacy loss budget is at most $\\epsilon = 1$, and we are partitioning our budget evenly amongst three queries,\n",
    "then each query will be calibrated to satisfy $\\epsilon = \\frac{1}{3}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Submit DP Queries\n",
    "\n",
    "It is now time to create differentially private releases.\n",
    "The following query counts the number of records in the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_query = (\n",
    "    context.query()\n",
    "    .split_dataframe(\",\", col_names=col_names)\n",
    "    .select_column(\"age\", str) # temporary until OpenDP 0.10 (Polars dataframe)\n",
    "    .count()\n",
    "    .laplace()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library uses the privacy unit and the query itself \n",
    "to determine the smallest amount of noise to add that will still satisfy the per-query privacy loss.\n",
    "Given these constraints, noise will be added to the count query with a scale of 3 (standard deviation of ~4.2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0000000000000004"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = count_query.param()\n",
    "scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the underlying mathematics that leads to this noise scale: if a teacher contributes at most one row, \n",
    "then the sensitivity of the count is one, \n",
    "because the addition or removal of a teacher can change the count by at most one.\n",
    "With the Laplace Mechanism, the noise scale (3) is the sensitivity (1) divided by the per-query privacy loss ($\\epsilon = \\frac{1}{3}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create an accuracy estimate that is true at a $(1 - \\alpha)100$% confidence level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.445721638273584"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = dp.discrete_laplacian_scale_to_accuracy(scale=scale, alpha=0.05)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the discrete Laplace distribution's scale is 3, the DP estimate differs from the exact estimate by no more than 9.45 with 95% confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the accuracy of the query seems reasonable, then make a private release.\n",
    "Keep in mind, this action will permanently consume one of `context`'s three queries we allocated when we launched the context API \n",
    "(each of which uses 1/3 of our privacy-loss budget)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6999"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_count = count_query.release()\n",
    "dp_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a random draw from the discrete Laplace distribution, centered at the true count of the number of records in the underlying dataset (7000).\n",
    "Your previous accuracy estimate can now be used to create a confidence interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6989.554278361727, 7008.445721638273)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_count - accuracy, dp_count + accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exact count lies within the interval with 95% confidence.\n",
    "\n",
    "This concludes the process of making a DP release.\n",
    "\n",
    "Let's repeat this process more briefly for estimating the mean age.\n",
    "This time we benefit from having a DP count estimate in our public information:\n",
    "It is used to help calibrate the privacy guarantees for the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_query = (\n",
    "    context.query()\n",
    "    .split_dataframe(\",\", col_names=col_names)\n",
    "    .select_column(\"age\", str)\n",
    "    .cast_default(float)\n",
    "    .clamp((18.0, 70.0))  # a best-guess based on public information\n",
    "    # Explanation for `constant=42`:\n",
    "    #    since dp_count may be larger than the true size, \n",
    "    #    imputed rows will be given an age of 42.0 \n",
    "    #    (also a best guess based on public information)\n",
    "    .resize(size=dp_count, constant=42.0)\n",
    "    .mean()\n",
    "    .laplace()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This measurement involves more preprocessing than the count did (casting, clamping, and resizing).\n",
    "The purpose of this preprocessing is to bound the sensitivity of the mean: \n",
    "the mean should only ever change by a small amount when any teacher is added or removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.327593142035525"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_query.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OpenDP Library supports more statistics, \n",
    "like the variance, various ways to compute histograms and quantiles, and PCA.\n",
    "The library also supports other mechanisms like the Gaussian Mechanism, \n",
    "which provides tighter privacy accounting when releasing a large number of queries,\n",
    "the thresholded Laplace Mechanism, for releasing counts on data sets with unknown key sets,\n",
    "and variations of randomized response.\n",
    "\n",
    "[[Transformations]](https://docs.opendp.org/en/stable/user/transformations.html)\n",
    "[[Measurements]](https://docs.opendp.org/en/stable/user/measurements.html)\n",
    "[[Example PUMS Analysis]](https://docs.opendp.org/en/stable/examples/pums-data-analysis.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framework API\n",
    "\n",
    "The OpenDP Library has two APIs:\n",
    "* the _Context API_, shown above, which is simpler and helps to enforce best practices\n",
    "* the _Framework API_, which is lower-level, and directly follows the OpenDP programming framework\n",
    "\n",
    "The Context API is less flexible than the Framework API, \n",
    "because the Context API is a wrapper around the Framework API: \n",
    "All calls ultimately pass through the Framework API.\n",
    "\n",
    "The following sections show how the prior analysis looks in the Framework API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Privacy Unit\n",
    "\n",
    "The privacy unit is actually a 2-tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_metric, d_in = privacy_unit\n",
    "\n",
    "assert d_in == 1 # neighboring dataset distance is at most d_in...\n",
    "assert input_metric == dp.symmetric_distance() # ...in terms of additions/removals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The privacy unit tuple specifies how distances are computed between two datasets (input_metric), and how large the distance can be ($d_{in}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Privacy Loss\n",
    "\n",
    "The privacy loss is also a 2-tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "privacy_measure, d_out = privacy_loss\n",
    "\n",
    "assert d_out == 1. # output distributions have distance at most d_out (Îµ)...\n",
    "assert privacy_measure == dp.max_divergence(T=float) # ...in terms of pure-DP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The privacy loss tuple specifies how distances are measured between distributions (privacy_measure), and how large the distance can be ($d_{out}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Mediate Access to Data\n",
    "\n",
    "`dp.Context.compositor` creates a sequential composition measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_sc = dp.c.make_sequential_composition(\n",
    "    # dataset is a single string, with rows separated by linebreaks\n",
    "    input_domain=dp.atom_domain(T=str),\n",
    "    input_metric=input_metric,\n",
    "    output_measure=privacy_measure,\n",
    "    d_in=d_in,\n",
    "    d_mids=[d_out / 3] * 3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The measurement is called with the data to create a compositor queryable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "qbl_sc = m_sc(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now submit up to three queries to `qbl_sc`, in the form of measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Submit DP Queries\n",
    "\n",
    "First, create a count query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_count = (\n",
    "    dp.t.make_split_dataframe(\",\", col_names=col_names)\n",
    "    >> dp.t.make_select_column(\"age\", str)\n",
    "    >> dp.t.then_count()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `>>` is a shorthand for _chaining_, or functional composition\n",
    "* `then_*` uses the input domain and input metric from the prior transformation\n",
    "\n",
    "With this lower-level API you get greater flexibility. For instance, you can see the sensitivity of the count query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_sensitivity = t_count.map(d_in)\n",
    "count_sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A binary search is used to find the smallest noise scale that results in a measurement that satisfies $\\epsilon = \\frac{1}{3}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_count = dp.binary_search_chain(\n",
    "    lambda scale: t_count >> dp.m.then_laplace(scale), d_in, d_out / 3\n",
    ")\n",
    "dp_count = qbl_sc(m_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, construct a mean measurement and release it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.347899010945284"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_mean = (\n",
    "    dp.t.make_split_dataframe(\",\", col_names=col_names) >>\n",
    "    dp.t.make_select_column(\"age\", str) >>\n",
    "    dp.t.then_cast_default(float) >>\n",
    "    dp.t.then_clamp((18.0, 70.0)) >>  # a best-guess based on public information\n",
    "    dp.t.then_resize(size=dp_count, constant=42.0) >>\n",
    "    dp.t.then_mean()\n",
    ")\n",
    "\n",
    "m_mean = dp.binary_search_chain(\n",
    "    lambda scale: t_mean >> dp.m.then_laplace(scale), d_in, d_out / 3\n",
    ")\n",
    "\n",
    "qbl_sc(m_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

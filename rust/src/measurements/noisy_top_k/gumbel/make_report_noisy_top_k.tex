\documentclass{article} 
\input{../../../lib.sty} 
\allowdisplaybreaks

\title{\texttt{fn make\_noisy\_top\_k}} 
\author{Michael Shoemate} 
\begin{document}  
\maketitle 
 
Proves soundness of \rustdoc{measurements/fn}{make\_noisy\_top\_k}  
in \asOfCommit{mod.rs}{f5bb719}.\\ 
\texttt{make\_noisy\_top\_k} returns a Measurement that  
noisily selects the index of the greatest score from a vector of input scores. 
This released index can be later be used to index into a public candidate set (postprocessing). 
 
\section{Background}
This mechanism fulfills the same purpose as the exponential mechanism, 
where the release is the best candidate's index from a finite set.
The naive implementation of the exponential mechanism samples an index $k$ from $[m] = {1, \ldots, m}$, 
where $m$ is the number of candidates,
with probability $p_i$ assigned to each candidate's index $i$ as a function of their score $s_i$.
The output is drawn via inverse transform sampling
by outputting the smallest index $k$ for which the cumulative probability is greater than some $u \sim \mathrm{Uniform}(0, 1)$. 
\begin{equation}  
    \label{m-naive}  
    \mathcal{M}_{\mathrm{naive}}([s_1, \ldots, s_m]) = \min \{k: \sum_{i=1}^k p_i \ge u \}
\end{equation}
 
The probability of index $k$ being selected is the normalization of its likelihood $\exp(s_k / \tau)$. 
As a candidate's score $s_k$ increases, the candidate becomes exponentially more likely to be selected:
\begin{equation} 
    \label{prob-of-k} 
    p_k = \frac{\exp(s_k / \tau)}{\sum_{i = 1}^m \exp(s_i / \tau)} 
\end{equation} 
 
This equation introduces a new temperature parameter, $\tau$, 
which calibrates how distinguishable scores are from each other. 
As temperature increases, the categorical output distribution tends towards higher entropy/uniformity and becomes more privacy preserving. 
As temperature decreases, the categorical distribution tends towards a one-hot vector 
(where each candidate has zero probability, except for the candidate with the maximum score, which has probability one), 
becoming less private. 
Temperature is related to the privacy loss parameter (\dout) and sensitivity of the scoring function ($\Delta$) as follows: 
 
\begin{equation} 
    \tau = \Delta / \dout
\end{equation} 

A precise definition of $\Delta$ will come later and is captured by the metrics we use on the score vector $s = [s_1, \ldots, s_m]$.
When $\dout$ increases, temperature decreases, and candidates become more distinguishable from each other. 
We also divide scores by their global sensitivity to normalize the sensitivity to one. 
In the differential privacy literature for the exponential mechanism, the sensitivity is often multiplied by two. 
In OpenDP's \texttt{make\_noisy\_top\_k} this factor is bundled into the $\Delta$ term, which is expressed in terms of a metric that captures monotonicity. 
 
\subsection{Sampling Vulnerabilities} 
 
In practice, computing $\exp(s_i / \tau)$ is prone to 
zero underflow (where a non-zero quantity rounds down to zero) 
and overflow (where a large finite quantity is replaced with infinity) 
due to finite/limited data representation.  
Specifically, a scaled score $s_i / \tau$ of just $-709$ underflows to zero and $+710$ overflows to infinity when stored in a 64-bit float.  

A simple improvement is to shift the scores by subtracting the greatest score from all scores. 
In idealized arithmetic, the resulting probabilities are not affected by shifts in the underlying scores. 
On finite data types, this shift prevents a catastrophic overflow, but makes underflow more likely,  
causing tail values of the distribution to round to zero.  
The inverse transform sampling step is also subject to accumulated rounding errors from the arithmetic and sum,  
which influence the likelihood of being chosen. 

These potential vulnerabilities can be addressed via the Gumbel-max trick.
The naive mechanism $\mathcal{M}_\mathrm{naive}$ implemented with infinite-precision arithmetic
is equivalent in distribution to the following mechanism:
\begin{equation} 
    \mathcal{M}([s_1, \ldots, s_m]) = \mathrm{argmax}_i g_i,
\end{equation}
where each $g_i \sim \mathrm{Gumbel}(\mu = s_i, \beta = \tau)$.
 
\subsection{Noise Distribution} 
\texttt{make\_noisy\_top\_k} can also be configured to satisfy 
either \rustdoc{measures/struct}{MaxDivergence} or \rustdoc{measures/struct}{ZeroConcentratedDivergence}.
Gumbel noise is used when \texttt{output\_measure} is \texttt{ZeroConcentratedDivergence},
and exponential noise is used when \texttt{output\_measure} is \texttt{MaxDivergence}.
These choices of noise distributions minimize the necessary noise variance for their respective privacy measures.

\section{Hoare Triple} 
\subsection*{Precondition} 
\subsubsection*{Compiler-verified}
\begin{itemize} 
    \item \texttt{MO} is a type with trait \rustdoc{measurements/make\_noisy\_top\_k/trait}{TopKMeasure}
    \item \texttt{TIA} (atomic input type) is a type with trait \rustdoc{traits/trait}{Number}
\end{itemize} 

\subsubsection*{Caller-verified}
None
 
\subsection*{Pseudocode} 
\label{sec:python-pseudocode} 
\lstinputlisting[language=Python,firstline=2,escapechar=|]{./pseudocode/make_noisy_top_k.py} 
 
\subsection*{Postcondition} 
 
\begin{theorem}
    \label{postcondition}
    \validMeasurement{\texttt{input\_domain, input\_metric, output\_measure, k, scale, optimize, MO, TIA}}{\texttt{make\_noisy\_top\_k}}  
\end{theorem}
 
\section{Proof} 

\subsection{Data-independent runtime errors.}
There are two sources of runtime errors in the function:

\texttt{greater\_than}, which can in turn only occur due to lack of system entropy.
This kind of failure is generally considered data-independent, where a lack of system entropy would occur regardless of the choice of input datasets.
However, failure due to lack of entropy can be data-dependent in this case.

An input score vector with all the same scores 
is expected to require more draws from the random number generator,
as the candidates will be very competitive, 
as compared to a score vector with widely different scores. 
This technically results in input datasets with more homogeneity being more likely to exhaust entropy and raise an error,
violating the data-independent runtime error requirement.
This is an unlikely exploit in practice, due to the difficulty of exhausting the RNG's entropy.

The data-independent runtime error requirement is otherwise satisfied.

\subsection{Privacy Guarantee} 

\begin{definition}
    \label{def:mechanism}
    $\mathcal{M}_{\mathrm{RV}}(x)$ is a noninteractive mechanism that,
    when passed a vector of non-null scores,
    returns the indices of the top $k$ noisy processed scores $z_i$,
    where each $z_i \sim \mathrm{RV}(\mathrm{shift}=y_i, \mathrm{scale}=\texttt{scale})$,
    and each $y_i = -x_i$ if \texttt{optimize} is \texttt{min}, else $y_i = x_i$.
\end{definition}
 
\begin{theorem}
    \label{fn-implementation-equivalence}
    \function implements $\mathcal{M}$.

    \function will return a data-dependent error if entropy is exhausted.
    Otherwise the returned function will only error if there are no non-null scores.
\end{theorem}

\begin{proof}[Proof of Theorem~\ref{fn-implementation-equivalence}]
    By line~\ref{check-non-negative-scale} the scale is non-negative.

    If scale is zero, then since the preconditions for \rustdoc{measurements/noisy_top_k/fn}{function\_top\_k} are met,
    then by its postcondition, since scale is zero, \function is equivalent to $\mathcal{M}_\mathrm{RV}(x)$ as defined in \ref{def:mechanism}.
    This is because RV is from a location-scale family of distributions, and the scale parameter is zero.

    If scale is positive, then since the preconditions for \rustdoc{measurements/report_noisy_top_k/fn}{function\_noisy\_top\_k} are met,
    then by its postcondition, since scale is positive, \function is equivalent to $\mathcal{M}_\mathrm{RV}(x)$.

    Therefore, \function is equivalent to $\mathcal{M}_\mathrm{RV}(x)$.
\end{proof}

\begin{proof}[Proof for \ref{postcondition} Privacy Guarantee]
    The privacy map is defined on line \ref{fn-privacy-map}.
    \din denotes the greatest distance between adjacent score vectors in terms of the \rustdoc{metrics/struct}{LInfDistance} metric.
    By the postcondition of \rustdoc{metrics/struct}{LInfDistance}\texttt{.range\_distance}, \texttt{d\_in} is converted to the range distance,
    and on line \ref{fn-inf-cast} the distance type is conservatively casted to float.

    By Theorem~\ref{fn-implementation-equivalence}, \function implements $\mathcal{M}_\mathrm{RV}$,
    where RV denotes the associated noise distribution of \texttt{output\_measure} as defined in \rustdoc{measurements/make\_noisy\_top\_k/trait}{SelectionMeasure}.
    Since \din denotes the range distance, and \function implements $\mathcal{M}_\mathrm{RV}$,
    then the preconditions for \rustdoc{measurements/make\_noisy\_top\_k/trait}{SelectionMeasure}\texttt{.privacy\_map} on line \ref{fn-privacy-map-call} are met.
    The postcondition on the value returned is then consistent with the privacy guarantee of the mechanism.
\end{proof} 
 
\bibliographystyle{plain} 
\bibliography{references.bib} 
 
\end{document} 

\documentclass{article}
\input{../../lib.sty}

\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}

\title{\texttt{fn make\_randomized\_response\_bitvec}}
\author{Abigail Gentle}

\allowdisplaybreaks

\begin{document}

\maketitle



\contrib

Proves soundness of \rustdoc{measurements/fn}{make\_randomized\_response\_bitvec} in \asOfCommit{mod.rs}{cfd1bec5}.

\section{Introduction}
RAPPOR is a protocol for local differentially private (DP) frequency estimation. In the local model, each user is guaranteed $\varepsilon$-DP for their response. This is achieved by computing the \texttt{xor} of each input vector with a noise vector. Because the noise is added mechanically we can efficiently account for the bias introduced with the function \rustdoc{measurements/fn}{debias\_randomized\_response\_bitvec}, which sums and normalises a vector of private outputs.

In the simplest case, each category is represented by an index $i\in[k]$, where $[k]=\{0,1,\ldots,k-1\}$, and each row with non-empty category $i$ is transformed into a one-hot vector which has 0's everywhere and a 1 at index $i$. Therefore, the number of set bits in the input is 1, and the input domain should be a \rustdoc{domains/struct}{BitVectorDomain} with $\texttt{max\_weight}=1$. \textcolor{red}{Vikrant: I would define $m$ here, and then explain through the two examples you have provided. Otherwise, the reader will have to search for its meaning while reading the actual proofs. Let's just also mention somewhere that $2m+1 \leq k$, as we had discussed on GitHub.}

In order to estimate the frequencies of strings drawn from a potentially unbounded set, inputs can also be hashed onto a Bloom filter using $h<k$ hash functions. As such the number of set bits is at most $h$ and the input domain should be a \rustdoc{domains/struct}{BitVectorDomain} with $\texttt{max\_weight}=h$. As we demonstrate in Theorem~\ref{thm:privacy-parameter}, the privacy of the protocol will degrade linearly with the number of hash functions used (although the hash functions will make the life of an adversary trickier, as each bit set in the Bloom filter could map to multiple possible strings).



\section{Hoare Triple}
\subsection{Preconditions}
\begin{itemize}
	\item Variable \texttt{input\_domain} must be of type \rustdoc{domains/struct}{BitVectorDomain}, with \texttt{max\_weight}.
	\item Variable \texttt{input\_metric} must be of type \rustdoc{metrics/struct}{DiscreteDistance}.
	\item Variable \texttt{f} must be of type \texttt{f64}.
    \item Variable \texttt{constant\_time} must be of type \texttt{bool}.
\end{itemize}

\subsection{Pseudocode}

\lstinputlisting[language=Python,firstline=2,escapechar=|]{./pseudocode/make_randomized_response_bitvec.py}

\subsection{Postcondition}
\validMeasurement{\texttt{(f, m, constant\_time)}}{\\ \texttt{make\_randomized\_response\_bitvec}}


\section{Proof}

\subsection{Privacy}

\begin{tcolorbox}
\begin{note}[Proof relies on correctness of Bernoulli sampler]
The following proof makes use of the following lemma that asserts the correctness of the Bernoulli sampler function.
    \begin{lemma}
    If system entropy is not sufficient, \texttt{sample\_bernoulli} raises an error. 
    Otherwise, \texttt{sample\_bernoulli(f/2, constant\_time)}, the Bernoulli sampler function used in \texttt{make\_randomized\_response\_bool}, 
    returns \texttt{true} with probability (\texttt{prob}) and returns  \texttt{false} with probability (1 - \texttt{f/2}).
    \end{lemma}
\end{note}
\end{tcolorbox}
\begin{theorem}[\cite{rappor}]
\label{thm:privacy-parameter}
	The program \rustdoc{measurements/fn}{make\_randomized\_response\_bitvec} satisfies $\varepsilon$-DP, where 
	\begin{equation*}
		\varepsilon = 2m\log\left(\frac{2-f}{f}\right).
	\end{equation*}
\end{theorem}
\begin{lemma}
    We have the following for the output of the algorithm.
	\begin{align}
		\mathbb{P}[y_i = 1~|~x_i=1] &= 1 - \frac{1}{2}f\\
		\mathbb{P}[y_i = 1~|~x_i=0] &=\frac{1}{2}f
	\end{align}
\end{lemma}
\begin{proof}
	Let $Y=(y_1,\ldots,y_k)$ be a randomised report generated by \rustdoc{measurements/fn}{make\_randomized\_response\_bitvec}. Then the probability of observing any given report $Y$ is $\mathbb{P}[Y=y | X=x]$. Suppose $x=(x_1,\ldots,x_k)$ is a single Boolean vector with at most $m$ ones. 
	Without loss of generality assume that $x^*=(x_1=1,\ldots,x_m=1,x_{m+1}=0,\ldots,x_k=0)$, then we have
	\begin{align*}
		\mathbb{P}[Y=y~|~X=x^*] &=%
			\prod\limits_{i=1}^m \left(\frac{1}{2}f\right)^{1-y_i}\left(1-\frac{1}{2}f\right)^{y_i}%
			\times \prod\limits_{i=m+1}^k\left(\frac{1}{2}f\right)^{y_i} \left(1-\frac{1}{2}f\right)^{1-y_i}.
	\end{align*}
	Then let $D$ be the ratio of two such conditional probabilities with distinct values $x_1$ and $x_2$, and let $S$ be the range of \rustdoc{measurements/fn}{make\_randomized\_response\_bitvec}. \textcolor{red}{Vikrant: The notations $x_1,x_2$ are getting overloaded in the following, I believe. If they're denoting neighbouring vectors, I would just use $x,x'$.}
	\begin{align}
		D &= \frac{\mathbb{P}[Y\in S~|~X=x_1]}{\mathbb{P}[Y\in S~|~X=x_2]}\\
			&= \frac{\sum_{y\in S}\mathbb{P}[Y=y~|~X=x_1]}{\sum_{y\in S}\mathbb{P}[Y=y~|~X=x_2]}\nonumber\\
			&\leq \max_{y\in S}\frac{\mathbb{P}[Y=y~|~X=x_1]}{\mathbb{P}[Y=y~|~X=x_2]}\nonumber\\
			&=\max_{y\in S}\frac{%
				\prod\limits_{i=1}^m \left(\frac{1}{2}f\right)^{1-y_i}\left(1-\frac{1}{2}f\right)^{y_i}%
				\times \prod\limits_{i=m+1}^k\left(\frac{1}{2}f\right)^{y_i} \left(1-\frac{1}{2}f\right)^{1-y_i}
			}{%
				\prod\limits_{i=1}^m \left(\frac{1}{2}f\right)^{y_i}\left(1-\frac{1}{2}f\right)^{1-y_i}%
				\times \prod\limits_{i=m+1}^{2m}\left(\frac{1}{2}f\right)^{1-y_i} \left(1-\frac{1}{2}f\right)^{y_i}\times%
				\prod\limits_{i=2m+1}^{k}\left(\frac{1}{2}f\right)^{y_i}\left(1-\frac{1}{2}f\right)^{1-y_i}
			}\nonumber\\
			&=\max_{y\in S}\frac{%
				\prod\limits_{i=1}^m \left(\frac{1}{2}f\right)^{1-y_i}\left(1-\frac{1}{2}f\right)^{y_i}%
				\times \prod\limits_{i=m+1}^{2m}\left(\frac{1}{2}f\right)^{y_i} \left(1-\frac{1}{2}f\right)^{1-y_i}%
			}{%
				\prod\limits_{i=1}^m \left(\frac{1}{2}f\right)^{y_i}\left(1-\frac{1}{2}f\right)^{1-y_i}%
				\times \prod\limits_{i=m+1}^{2m}\left(\frac{1}{2}f\right)^{1-y_i} \left(1-\frac{1}{2}f\right)^{y_i}%
			}\label{eq:privacy:cancel-k}\\
			&=\max_{y\in S}\left[%
				\prod\limits_{i=1}^m \left(\frac{1}{2}f\right)^{2(1-y_i)}\left(1-\frac{1}{2}f\right)^{2y_i}%
				\times \prod\limits_{i=m+1}^{2m}\left(\frac{1}{2}f\right)^{2y_i} \left(1-\frac{1}{2}f\right)^{2(1-y_i)}\right]\label{eq:maximise-product}%
	\end{align}
	Notice that, by Equation~\ref{eq:privacy:cancel-k}, the privacy is not dependent on $k$ and Equation~\ref{eq:maximise-product} is maximised when $y_1=1,\ldots,y_m=1$, and $y_{m+1},\ldots,y_{2m}=0$, giving
	\begin{align*}
		D &\leq \left(1-\frac{1}{2}f\right)^{2m}\times\left(\frac{1}{2}f\right)^{-2m}\\
			&= \left(\frac{2-f}{f}\right)^{2m}
	\end{align*}
	Therefore,
	\begin{equation}
		\varepsilon \leq 2m\log\left(\frac{2-f}{f}\right),
	\end{equation}
    which completes the proof.
\end{proof}

\subsection{Utility}

\begin{theorem}
\label{thm:unbiased-estimator}
	The program \rustdoc{measurements/fn}{debias\_randomized\_response\_bitvec} is an unbiased frequency estimator.
\end{theorem}
\begin{proof} We denote the input domain as $X$, which is the set of all vectors with hamming weight at most $m$. The set of all users is $X^n$, where each user $x_1,\ldots,x_n$ holds a single input. \textcolor{red}{Vikrant: We are overloading the notation $x$ quite a bit. In the previous subsection, we said $x_i$ is essentially a $k$-dimensional vector that is each user's data, but now, we are saying that $x_i$ is every user's data. There is a mismatch. I would change the notation a bit in the previous subsection, or introduce superscripts to make it less confusing. Also, ``single input'' is confusing. what does that mean here? Does every user just contribute one bit or $m$ bits?} Each input $x_j$ is transformed into $y_j$ using \rustdoc{measurements/fn}{make\_randomized\_response\_bitvec}. Let $Y$ be the sum of $n$ received outputs, where $Y_i=\sum_{j=1}^n y_i$ is the number of received bits at index $i\in [k]$. Let $N_i=\sum x_{j,i}$ be the true (non-private) count vector of users with bit $i$ set. Our goal is to estimate the frequencies $q_i=N_i/n$ with minimal error. $Y_i$ is a sum of two binomials
\begin{align}
\mathbb{E}[Y_i] &= \mathbb{E}\left[\text{Bin}\left(N_i,1-\frac{f}{2}\right)+\text{Bin}\left(n-N_i,\frac{f}{2}\right)\right]\label{eq:YsumBin}\\
    &=N_i\left(1-\frac{1}{2}f\right) + (n-N_i)\frac{f}{2}\label{eq:expec-Y}.
\end{align}
Therefore, by rearranging (\ref{eq:expec-Y}) we obtain an unbiased estimator for $\hat{N_i}$,
\begin{equation}
    \label{eq:estimator}
    \hat{N_i} = \frac{Y_i-n\frac{f}{2}}{1-f}.
\end{equation}

Our goal, however, is to estimate the frequency of each element $\hat{q}_i$ so we need to normalise by dividing by $n$, which gives us
\[
\hat{q_i}=\frac{\mathbb{E}[\hat{N}_i]}{n} = \frac{\frac{Y_i}{n}-\frac{f}{2}}{1-f}.
\]
This completes our proof.
\end{proof}

\begin{theorem}
	The program \rustdoc{measurements/fn}{debias\_randomized\_response\_bitvec} is a frequency estimator with mean squared error
	\begin{equation*}
		\mathbb{E}[\|q-\hat{q}\|_2^2] = \frac{k\left(f-\frac{f^2}{2}\right)}{2n(1-f)^2}.
	\end{equation*}
\end{theorem}
\begin{proof}
    Let $q = q(X^n)=\sum\limits_{j=1}^n x_j$ be the non private frequency vector of inputs. Our goal is to find the mean squared error of our estimate from this vector. Using the fact from Equation~\ref{eq:YsumBin} that $Y_i$ is a sum of two Binomials with equal variance (by the symmetry of their probabilities), we get the following.
\begin{align*}
    \text{Var}(Y_i) &= n\frac{f}{2}\left(1-\frac{f}{2}\right) \numberthis \label{eq:varianceY}\\
    \mathbb{E}[\|\hat{q}-q\|_2^2] &= \mathbb{E}\left[\sum\limits_{i=1}^k(\hat{q_i}-q_i)^2\right] = \sum\limits_{i=1}^k\mathbb{E}[(\hat{q_i}-q_i)^2] \\
			&= \sum\limits_{i=1}^k\mathbb{E}[(\hat{q_i}-\mathbb{E}[\hat{q_i}])^2] \tag{By Theorem~\ref{thm:unbiased-estimator}}\\
			&= \sum\limits_{i=1}^k\text{Var}(\hat{q_i}) = \sum\limits_{i=1}^k\text{Var}\left(\frac{\frac{\hat{Y_i}}{n}-\frac{f}{2}}{1-f}\right) \tag{By Equation~\ref{eq:estimator}}\\
			&= \sum\limits_{i=1}^k\text{Var}\left(\frac{Y_i}{n(1-f)}\right) \\
			&= \sum\limits_{i=1}^k\frac{\text{Var}(Y_i)}{n^2(1-f)^2}\\
			&= k\left(\frac{n\frac{f}{2}\left(1-\frac{f}{2}\right)}{n^2(1-f)^2}\right) \tag{By Equation~\ref{eq:varianceY}}\\
			& = \frac{k\left(f-\frac{f^2}{2}\right)}{2n(1-f)^2}
\end{align*}
This completes the proof.
\end{proof}

\bibliographystyle{plain}
\bibliography{references.bib}
\end{document}
\documentclass[11pt,a4paper]{article}
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{enumerate} 
\usepackage{physics}
\usepackage{enumerate}
\usepackage{fancyhdr}
 \usepackage{hyperref}
 \usepackage{tcolorbox}
\hypersetup{colorlinks,
    linkcolor=blue,
    citecolor=blue,      
    urlcolor=blue,
}
\usepackage{graphicx}


\oddsidemargin0.1cm 
\evensidemargin0.8cm
\textheight22.7cm 
\textwidth15cm \topmargin-0.5cm

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}

\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

\newcommand{\vicki}[1]{{ {\color{olive}{(vicki)~#1}}}}
\newcommand{\hanwen}[1]{{ {\color{purple}{(hanwen)~#1}}}}
\newcommand{\zach}[1]{{ {\color{red}{(zach)~#1}}}}

\newcommand{\MultiSet}{\mathrm{MultiSet}}
\newcommand{\len}{\mathrm{len}}
\newcommand{\din}{\texttt{d\_in}}
\newcommand{\dout}{\texttt{d\_out}}
\newcommand{\T}{\texttt{T} }
\newcommand{\F}{\texttt{F} }
\newcommand{\Relation}{\texttt{Relation}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\Y}{\mathcal{Y}}
\newcommand{\True}{\texttt{True}}
\newcommand{\False}{\texttt{False}}
\newcommand{\clamp}{\texttt{clamp}}
\newcommand{\function}{\texttt{function}}
\newcommand{\float}{\texttt{float }}
\newcommand{\questionc}[1]{\textcolor{red}{\textbf{Question:} #1}}

\newtheorem{corollary}{Corollary}
\newtheorem{proposition}{Proposition}

\theoremstyle{definition}
\newtheorem{remark}{Remark}
\newtheorem{definition}{Definition}
\newtheorem{observation}{Observation}
\newtheorem{note}{Note}
\newtheorem{hope}{Hope}
\newtheorem{warning}{Warning}
\newtheorem{problem}{Problem}
\newtheorem{fear}{Fear}
\newtheorem{question}{Question}

\title{Sampler Proofs for OpenDP: \texttt{sample\_bernoulli}}
\author{Vicki Xu, Hanwen Zhang, Zachary Ratliff}
\date{Summer 2022}
\begin{document}

\maketitle
\tableofcontents

%\begin{tcolorbox}
%\begin{warning}
%The \texttt{sample\_bernoulli} function relies on a cryptographic pseudorandom number generator (CSPRNG) provided by the \href{https://www.openssl.org/docs/man1.1.1/man3/RAND_bytes.html}{OpenSSL library}. As a result, measurements that use $\texttt{sample\_bernoulli}$ as their source of randomness will at most satisfy \emph{computational} differential privacy parameterized by a security parameter $\lambda$ (where the OpenSSL security parameter defaults to $\lambda = 256$ bits). 
%\end{warning}
%\end{tcolorbox}

\begin{tcolorbox}
\begin{warning}[Code is not constant-time]
 \texttt{sample\_bernoulli} takes in a boolean \texttt{constant\_time} parameter to protect against timing attacks on the Bernoulli sampling procedure. However, the current implementation does not guard against other types of timing side-channels that can break differential privacy, e.g., non-constant time code execution due to branching.
\end{warning}
\end{tcolorbox}

\section{Algorithm Implementation}
\subsection{Code in Rust}

The current OpenDP library contains the \texttt{sample\_bernoulli} function, which returns a draw from a Bernoulli distribution with parameter \texttt{prob}. This is defined in lines 59-92 of the file \texttt{mod.rs} in the Git repository \url{https://github.com/opendp/opendp/blob/main/rust/src/traits/samplers/bernoulli/mod.rs#L59-L92}. 

%\texttt{sample\_bernoulli} accepts a parameter \texttt{prob} of generic type \texttt{T} and another parameter \texttt{constant\_time} of type \texttt{bool}. As aforementioned, \texttt{prob} is the parameter for the draw from the distribution. \texttt{constant\_time} is an option for \texttt{sample\_bernoulli} to accomplish this draw in near-constant time, which mitigates timing attacks. This proof will not consider non-constant time.

%\texttt{sample\_bernoulli} makes use of the \texttt{sample\_geometric\_buffer} function. As defined in line \ref{line:geombuffer} of the pseudocode, \texttt{sample\_geometric\_buffer} declares a buffer \texttt{buf} with \texttt{buffer\_len} elements that is then filled using the \texttt{fill\_bytes} function. Then out of the nonzero elements of \texttt{buf}, \texttt{sample\_geometric\_buffer} treats \texttt{buf} as a string of bits and returns the zero-indexed position of the first $1$ (as in line \ref{line:indexcmp}) or \texttt{None} if no $1$'s are found in this string of bits. 

At a high level, \texttt{sample\_bernoulli} considers the binary expansion of \texttt{prob} into an infinite sequence $\texttt{a\_i}$, like so: $\texttt{prob} = \sum_{i = 0}^{\infty} \frac{a_i}{2^{i + 1}}$. The algorithm samples $I \sim Geom(0.5)$ using an internal function \texttt{sample\_geometric\_buffer}, then returns $a_I$. 

\section{Pseudocode \& Proofs}
For each function, we present a simplified Python-like pseudocode of the Rust implementation, followed by the proof. \vicki{later when we make this modular (i.e. sorted into functions relating to bernoulli, functions relating to geometric, etc.), each function will be a separate theorem.}

The necessary definitions for the pseudocode can be found at \href{https://github.com/opendp/whitepapers/blob/pseudocode-defns/pseudocode-defns/pseudocode_defns.pdf}{``List of definitions used in the pseudocode"}. The necessary definitions for the proof can be found at \href{https://github.com/opendp/whitepapers/blob/proof-defns/proof-defns/proof_defns.pdf}{``List of definitions used in the proofs"}. \vicki{need to fix these links} 

\subsubsection*{Preconditions}
To ensure the correctness of the output, we require the following preconditions:

\begin{itemize}
    \item \textbf{User-specified types:}
    \begin{itemize}
        \item Variable \texttt{prob} must be of type \texttt{T}
        \item Variable \texttt{constant\_time} must be of type \texttt{bool}
        \item Type \texttt{T} has traits \texttt{Copy}, \texttt{One}, \texttt{Zero}, \texttt{PartialOrd}, and \texttt{FloatBits}
        \item Type \texttt{T::Bits} has traits \texttt{PartialOrd} and \texttt{ExactIntCast<usize>}
        \item Type \texttt{usize} has trait \texttt{ExactIntCast<T::Bits>}
    \end{itemize}
\end{itemize}

\subsection{Pseudocode and proof for \texttt{sample\_geometric\_buffer}}
\begin{lstlisting}[language=Python, escapechar=|]
# returns a sample from the Geom(0.5) distribution
def sample_geometric_buffer(buffer_len : usize, constant_time : bool) -> Optional[uint]: |\label{line:geombuffer}|
    buf = bytearray(buffer_len)
    buf = fill_bytes(buf)
    
    if (constant_time): 
        ret = None
        for i in range(len(buf)):
            # find first nonzero event
            if (buf[i] > 0):
                # compute index of first nonzero bit buffer
                ret = 8 * i + leading_zeroes(buf[i]) |\label{line:indexcmp}|
        return ret
    else:
        for i in range(len(buf)):
            if (buf[i] > 0):
                return(8 * i + leading_zeroes(buf[i]))
        
        return None
\end{lstlisting}

\begin{tcolorbox}
\begin{theorem}[\texttt{sample\_geometric\_buffer}]
The function \texttt{sample\_geometric\_buffer(buffer\_len, constant\_time)} returns a random variable $X \sim CondGeom(0.5)$, a draw from a conditional Geometric distribution conditioned on the event that $Geom(0.5) < 8 \cdot \texttt{buffer\_len}$. Otherwise \texttt{sample\_geometric\_buffer} returns \texttt{None}. 
\end{theorem}
\end{tcolorbox}

\begin{proof}
We use the following theorem about the \texttt{fill\_bytes} function (\zach{insert link for \texttt{fill\_bytes} proof}).  

\begin{tcolorbox}
\begin{theorem}[\texttt{fill\_bytes}]
\texttt{fill\_bytes} accepts a buffer \texttt{buf} and fills it uniformly random and independent bytes such that each bit has probability $\frac{1}{2}$ of being set. Otherwise \texttt{fill\_bytes} throws an error. 
\end{theorem}
\end{tcolorbox}

The function \texttt{sample\_geometric\_buffer} uses \texttt{fill\_bytes}  as a subroutine to generate a buffer of $\texttt{buffer\_len}$ bytes where for each bit $b$ in the buffer it follows that $\Pr[b = 1] = \frac{1}{2}$ and $\Pr[b = 0] = \frac{1}{2}$ by Theorem 2.2. Conditioned on the event $E$, that there exists some bit in the buffer equal to $1$, the position of the \emph{first} such bit is a zero-indexed draw from the Geometric distribution $Geom(p)$ with $p = 0.5$ by definition of a Geometric random variable. If the event $E$ does not occur, the function returns \texttt{None}. 
\end{proof}

\subsection{Pseudocode and proof for \texttt{sample\_bernoulli}}

\begin{lstlisting}[language=Python, escapechar=|]
# returns a single bit with some probability of success
def sample_bernoulli(prob : T, constant_time : bool) -> bool:
    if (prob < 0 or prob > 1): |\label{line:rangecheck}|
        raise Exception("probability is not within [0, 1]")
        
    if prob is 1: |\label{line:1check}|
        return True
        
    # prepare for sampling first heads index by coin flipping
    max_coin_flips = exact_int_cast(T::EXPONENT_BIAS, usize) + exact_int_cast(T::MANTISSA_BITS) |\label{line:maxcoinflips}|
    
    # find number of bits to sample, rounding up to nearest byte (smallest sample size)
    buffer_len = inf_div(max_coin_flips, 8) |\label{line:bufferlen}|
    
    # repeatedly flip fair coin and identify 0-based index of first heads
    first_heads_index = sample_geometric_buffer(buffer_len, constant_time) |\label{line:sampling}|
    
    # if no events occurred, return early
    if first_heads_index is None: |\label{line:noones}|
        return False
    
    # find number of zeroes in binary rep. of prob
    leading_zeroes = T::EXPONENT_BIAS - 1 - raw_exponent(prob) |\label{line:leadingzeroes}|
    
    match first_heads_index: |\label{line:match}|
        # case 1: indexing into the leading zeroes
        case first_heads_index < leading_zeroes: |\label{line:case1}|
            return False
        # case 2: indexing into implicit bit directly to left of mantissa
        case first_heads_index == leading_zeroes: |\label{line:case2}|
            return (raw_exponent(prob) != 0)
        # case 3: indexing into out-of-bounds/implicitly-zero bits
        case first_heads_index > leading_zeroes + MANTISSA_BITS: |\label{line:case3}|
            return False
        # case 4: indexing into mantissa
        case _: |\label{line:case4}|
            return bool(bin(prob) & (1 << (MANTISSA_BITS + leading_zeroes - first_heads_index)))

\end{lstlisting}

\begin{tcolorbox}
\begin{theorem} For every setting of input parameters \texttt{prob, constant\_time} such that the preconditions hold, conditioned on no exceptions, \texttt{sample\_bernoulli} returns a value of \texttt{true} with probability \texttt{prob} and \texttt{false} with probability $1 - \texttt{prob}$. 
\end{theorem}
\end{tcolorbox}

\begin{proof} 
To show the correctness of \texttt{sample\_bernoulli} we observe first that the base-2 representation of \texttt{prob} is of the form 
\[
\texttt{leading\_zeroes || implicit\_bit || mantissa || trailing\_zeroes}
\]
and is represented \emph{exactly} as a normal floating-point number. The \href{https://en.wikipedia.org/wiki/IEEE_754}{IEEE-754 standard} represents a normal floating-point number using an exponent $E$, and a mantissa $m$, using a base-2 analog of scientific notation. 

\begin{definition}[Floating-Point Number]
A $(k,\ell)$-bit floating-point number $z$ is represented as
\[
z = (-1)^s \cdot (B.M) \cdot (2^E) 
\]
where
\begin{itemize}
    \item $s$ is used to represent the \emph{sign} of $z$
    \item $B$ is the implicit bit; $1$ for normal floating-point numbers and $0$ for subnormal floating point numbers
    \item $M \in \{0,1\}^k$ is a $k$-bit string representing the part of the mantissa to the right of the radix point, i.e.,
    \[
    1.M = \sum_{i = 1}^k M_i2^{-i}
    \]
    \item $E \in \mathbb{Z}$ represents the \emph{exponent} of $z$. When $\ell$ bits are allocated to representing $E$, then $E \in [-(2^{\ell - 1} - 2), 2^{\ell - 1}] \cap \mathbb{Z}$. Note that the range of $E$ is $2^\ell - 2$ rather than $2^\ell$ as the remaining to numbers are used to represent special floating point values. When $E = -(2^{\ell -1} - 2)$, then the floating point number is considered \emph{subnormal}. 
\end{itemize} 
\end{definition}

We now use the technique for \href{https://web.archive.org/web/20160418185834/https://amakelov.wordpress.com/2013/10/10/arbitrarily-biasing-a-coin-in-2-expected-tosses/}{arbitrarily biasing a coin in 2 expected tosses} as a building block. Recall that we can represent the probability $\texttt{prob}$ as $\texttt{prob} = \sum_{i = 0}^\infty \frac{a_i}{2^{i + 1}}$ for $a_i \in \{0, 1\}$, where $a_i$ is the zero-indexed $i$-th significant bit in the binary expansion of $\texttt{prob}$. Then let $I \sim Geom(0.5)$ and observe that the random variable $a_I$ is an exact Bernoulli sample with probability $\texttt{prob}$ since $P(a_I = 1) = \sum_{i = 0}^\infty P(a_i = 1|I = i)P(I = i) = \sum_{i = 1}^\infty a_i \cdot \frac{1}{2^{i + 1}} = \texttt{prob}$. It is therefore sufficient to show that for any $(k,\ell)$-bit float $\texttt{prob} = \sum_{i = 0}^\infty \frac{a_i}{2^{i + 1}}$, \texttt{sample\_bernoulli} returns the value $a_I$ with $I \sim Geom(0.5)$.

First, we observe that by line \ref{line:1check}, if $\texttt{prob} = 1.0$ then \texttt{sample\_bernoulli} returns \texttt{true} which is correct by definition of a Bernoulli random variable. Otherwise, the variable \texttt{max\_coin\_flips} is computed to be the value $\texttt{T::EXPONENT\_BIAS} + \texttt{T::MANTISSA\_BITS}$ which equals $2^{\ell - 1} - 1 + k$ for any $(k,\ell)$-bit float. Since \texttt{prob} has finite precision, there is some $j$ for which $a_i = 0$ for all $i > j$. For all $(k,\ell)$-bit floating-point numbers, $j \le 2^{\ell - 1} - 1 + k$ by definition. Then \texttt{sample\_bernoulli} calls \texttt{sample\_geometric\_buffer} with a buffer of length $\lceil \frac{\texttt{max\_coin\_flips}}{8}\rceil$ bytes (as shown in lines \ref{line:maxcoinflips} and \ref{line:bufferlen}) which returns  $\texttt{None}$ if and only if $I > {8\cdot \lceil \frac{2^{\ell - 1} -1 + k}{8}\rceil}$, where $I \sim Geom(0.5)$ (by Theorem 2.1). In this case, since $I > j$ this index appears in the \texttt{trailing\_zeroes} part of the binary expansion of \texttt{prob} and should always return \texttt{false}, i.e., $a_I = 0$ for all $I > j$. We can therefore restrict our attention to when \texttt{sample\_geometric\_buffer} returns an index $I \le \texttt{max\_coin\_flips}$ and show that \texttt{sample\_bernoulli} always returns $a_I$. 

Assuming that \texttt{sample\_geometric\_buffer} returns some $I < j$,  \texttt{sample\_bernoulli} computes the number of leading zeroes in the binary expansion of \texttt{prob} to be $\texttt{leading\_zeroes} = \texttt{T::EXPONENT\_BIAS} - 1 - \texttt{raw\_exponent(prob)}$, where \texttt{raw\_exponent(prob)} is the value stored in the $\ell$ bits of the exponent. This value is correct by the specification of a $(k,\ell)$-bit float.  \texttt{sample\_bernoulli} then matches on the value \texttt{first\_heads\_index} corresponding to $I \sim Geom(0.5)$ returned by the function \texttt{sample\_geometric\_buffer}: \\

\noindent\textbf{Case 1} ($\texttt{first\_heads\_index} < \texttt{leading\_zeroes}$). \\
\noindent This corresponds to \texttt{sample\_geometric\_buffer} returning a value $I$ such that $a_I$ indexes into the \texttt{leading\_zeroes} part of the  \texttt{prob} variable's binary expansion. Therefore, for any $I < \texttt{leading\_zeroes}$, it follows that $a_I = 0$ and we should return \texttt{false}. In this case, \texttt{sample\_bernoulli} returns \texttt{false}.\\

\noindent\textbf{Case 2} ($\texttt{first\_heads\_index} == \texttt{leading\_zeroes}$). \\
\noindent This corresponds to \texttt{sample\_geometric\_buffer} returning a value $I$ such that $a_I$ indexes into the \texttt{implicit\_bit} part of the  \texttt{prob} variable's binary expansion. When \texttt{prob} is a normal floating point value, i.e., $E \ne -(2^{\ell -1} - 2)$ then the implicit bit $a_I = 1$. Otherwise, when \texttt{prob} is a subnormal floating point value, i.e., $E = -(2^{\ell - 1} - 2)$, the implicit bit $a_I = 0$. Since \texttt{raw\_exponent(prob)} corresponds to the exponent $E$ for any $(k,\ell)$-bit floating point number \texttt{prob}, \texttt{sample\_bernoulli} returns \texttt{true} when $\texttt{raw\_exponent(prob)} \ne 0$ and \texttt{false} otherwise. \\


\noindent\textbf{Case 3} ($\texttt{leading\_zeroes}  + \texttt{T::MANTISSA\_BITS} < I$). This corresponds to the case where  \texttt{sample\_geometric\_buffer} returns a value $I$ where $I > j$, but $I < \texttt{max\_coin\_flips}$ and therefore $a_I$ indexes into the trailing zeroes. In this case, \texttt{sample\_bernoulli} returns \texttt{false} since $a_I = 0$ for all bits in the \texttt{trailing\_zeroes} part of \texttt{prob}'s binary expansion. \\

\noindent\textbf{Case 4} ($ \texttt{leading\_zeroes} < \texttt{first\_heads\_index}  <  \texttt{leading\_zeroes}  + \texttt{T::MANTISSA\_BITS}$). \\
\noindent This corresponds to \texttt{sample\_geometric\_buffer} returning a value $I$ such that $a_I$ indexes into the \texttt{mantissa} part of the  \texttt{prob} variable's binary expansion. In this case, 
\texttt{sample\_bernoulli}  left-shifts the value \texttt{1} by  $(\texttt{MANTISSA\_BITS + leading\_zeroes - first\_heads\_index})$ digits, the index into the mantissa corresponding to the digit $a_I$ in the binary representation of \texttt{prob}. Since the operation between the left-shifted \texttt{1} and the binary representation of \texttt{prob} at that position is a bitwise AND, if the bit in question is 1 (matching the left-shifted \texttt{1}), \texttt{sample\_bernoulli} will return \texttt{true}. Otherwise, \texttt{sample\_bernoulli} will return \texttt{false}. \\


\noindent Therefore, for any value of \texttt{prob}, the function \texttt{sample\_bernoulli} either raises an exception or returns the value \texttt{true} with probability exactly $\texttt{prob}$.  
\end{proof}

%\begin{proof}

%For all sampled $i$ from the truncated geometric, if $i > j$, the sampler will return false. This means $j$ is also the least number of bits that must be sampled using \texttt{sample\_geometric\_buffer} to accommodate that operation. Line \ref{line:maxcoinflips} calculates this $j$:
%\begin{align}
%    \texttt{max\_coin\_flips} = j & = \max_{\texttt{prob}}[\texttt{leading\_zeroes(prob)} + \texttt{MANTISSA\_BITS} + 1] \\
%    & = \max_{\texttt{prob}}[\texttt{EXPONENT\_BIAS} - 1 - \texttt{raw\_exponent(prob)} + \texttt{MANTISSA\_BITS} + 1] \\
%    & = (\texttt{EXPONENT\_BIAS} - 1) + (\texttt{MANTISSA\_BITS} + 1) \\
%    & = \texttt{EXPONENT\_BIAS} + \texttt{MANTISSA\_BITS}
%\end{align}


%(The transition from equation 1 to 2 is because the number of leading zeroes in the binary representation of \texttt{prob} is bounded in $[0, \texttt{EXPONENT\_BIAS} - 1]$ by the initial check for valid probability ($\in [0, 1]$) in line \ref{line:rangecheck} and the automatic return of \texttt{true} in line \ref{line:1check} when $\texttt{prob} = 1$. Therefore $\texttt{leading\_zeroes(prob)} = \texttt{EXPONENT\_BIAS} - 1 - \texttt{raw\_exponent(prob)}$.) 

%Since the smallest sample size is a byte, and we must sample at least $j$ bits, line \ref{line:bufferlen} rounds $j$ up to the nearest byte to calculate the length of the buffer array to pass to \texttt{sample\_geometric\_buffer}. 

%Using this information, line \ref{line:sampling} calls \texttt{sample\_geometric\_buffer} and automatically returns \texttt{false} if \texttt{sample\_geometric\_buffer} is not successful, because that implies the position of the first $1$ will be beyond $j$ digits. Otherwise, the position of the first $1$ is stored in \texttt{first\_heads\_index}. Line \ref{line:leadingzeroes} calculates the number of leading zeroes.

%Note that \texttt{sample\_bernoulli} returns $1$ if and only if the bit at position \texttt{first\_heads\_index} in the binary representation of \texttt{prob} equals $1$. Consider each case that that \texttt{first\_heads\_index} could match to: a bit in the leading zeroes, the implicit bit, the trailing zeroes, or the mantissa. The leading zeroes and the trailing zeroes both are by definition zero, and case 1 (line \ref{line:case1}) and 3 (line \ref{line:case3}) in the pseudocode, which handle position \texttt{first\_heads\_index} being in the leading or trailing zeroes, respectively, both return \texttt{false}. By IEEE-754 convention, when the raw exponent of a floating-point number is nonzero, the implicit bit is set; for case 2 (line \ref{line:case2}), which handles position \texttt{first\_heads\_index} being exactly the position of the implicit bit, \texttt{sample\_bernoulli} appropriately returns \texttt{true} when the exponent is nonzero and \texttt{false} otherwise. Note that in Rust, booleans are not implicitly integers (the way they might be in C or Python), so for cases 2 and 4 the Rust code handles type conversions for the zero-checking to return booleans. 

%For case 4 (line \ref{line:case4}), indexing into the mantissa, by left-shifting \texttt{1} a number of \texttt{MANTISSA\_BITS + leading\_zeroes - first\_heads\_index} digits, the position in the binary representation of \texttt{prob} that will be examined will be \texttt{first\_heads\_index}. Since the operation between the left-shifted \texttt{1} and the binary representation of \texttt{prob} at that position is \texttt{\&}, if the bit in question is 1 (matching the left-shifted \texttt{1}), \texttt{sample\_bernoulli} will return 1. Otherwise, \texttt{sample\_bernoulli} will return 0. 

%The validity of this approach comes from \href{https://web.archive.org/web/20160418185834/https://amakelov.wordpress.com/2013/10/10/arbitrarily-biasing-a-coin-in-2-expected-tosses/}{arbitrarily biasing a coin in 2 expected tosses}. Recall that $p = \sum_{i = 0}^\infty \frac{a_i}{2^{i + 1}}$ for $a_i \in \{0, 1\}$, where $a_i$ is the zero-indexed $i$-th significant bit in the binary expansion of $p$. Let $I$ be the number of fair coin tosses required for the coin to land heads. Note that the \texttt{sample\_bernoulli} algorithm samples $\texttt{first\_heads\_index} = I \sim Geom(0.5)$, and returns $a_I$.  We have that $P(a_I = 1) = \sum_{i = 0}^\infty P(a_i = 1|I = i)P(I = i) = \sum_{i = 1}^\infty a_i \cdot \frac{1}{2^{i + 1}} = p$, because $P(a_i = 1|I = i) = a_i$ and $P(I = i) = \frac{1}{2^{i + 1}}$ for all $i \in [1, \infty)$. 

%Therefore, \texttt{sample\_bernoulli} always returns $1$ with probability $p$. 




% \hanwen{not sure if this is helpful at all but i'm copying mike's response to all four cases here for reference:\\
% case 1 handles indexing into the leading zeros in a\_i\\
% case 2 is the implicit a\_i immediately to the left of the mantissa bits\\
% case 3 covers the infinite trailing zeros to the right of the mantissa bits\\
% case 4 is actually indexing into the mantissa bits.
% }
%\end{proof}

\end{document}


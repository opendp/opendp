
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>A Framework to Understand DP &#8212; OpenDP</title>
  <script>
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1e1de1a1873e13ef5536" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1e1de1a1873e13ef5536" rel="stylesheet">

  
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1e1de1a1873e13ef5536">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'user/programming-framework/a-framework-to-understand-dp';</script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Constructors" href="../constructors/index.html" />
    <link rel="prev" title="Supporting Elements" href="supporting-elements.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fa-solid fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../../index.html">

  
  
  
  
  
  
  

  
    <img src="../../_static/opendp-logo.png" class="logo__image only-light" alt="Logo image">
    <img src="../../_static/opendp-logo.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                <li class="nav-item">
                    <a class="nav-link" href="../../quickstart.html">
                        Quickstart
                    </a>
                </li>
                

                <li class="nav-item current active">
                    <a class="nav-link" href="../index.html">
                        User Guide
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../../examples/index.html">
                        Examples
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../../api/index.html">
                        API
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../../developer/index.html">
                        Developer Guide
                    </a>
                </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                <li class="nav-item">
                    <a class="nav-link" href="../../resources/index.html">
                        Resources
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../../opendp-commons/index.html">
                        OpenDP Commons
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../../contact.html">
                        Contact
                    </a>
                </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
    </div>

    <div id="navbar-end">
      <div class="navbar-end-item navbar-end__search-button-container">
        
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
      </div>
      
      <div class="navbar-end-item">
        <span class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" data-toggle="tooltip">
    <a class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="fa-regular fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></a>
</span>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          <a href="https://github.com/opendp" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-toggle="tooltip"><span><i class="fa-brands fa-square-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          <a href="https://twitter.com/opendp_org" title="Twitter" class="nav-link" rel="noopener" target="_blank" data-toggle="tooltip"><span><i class="fa-brands fa-square-twitter"></i></span>
            <label class="sr-only">Twitter</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          <a href="https://github.com/opendp/opendp/discussions" title="GitHub Discussions" class="nav-link" rel="noopener" target="_blank" data-toggle="tooltip"><span><i class="far fa-comments"></i></span>
            <label class="sr-only">GitHub Discussions</label></a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>


  
  <div class="search-button-container--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
  </div>

  
  <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
  </label>
  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                <li class="nav-item">
                    <a class="nav-link" href="../../quickstart.html">
                        Quickstart
                    </a>
                </li>
                

                <li class="nav-item current active">
                    <a class="nav-link" href="../index.html">
                        User Guide
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../../examples/index.html">
                        Examples
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../../api/index.html">
                        API
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../../developer/index.html">
                        Developer Guide
                    </a>
                </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                <li class="nav-item">
                    <a class="nav-link" href="../../resources/index.html">
                        Resources
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../../opendp-commons/index.html">
                        OpenDP Commons
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../../contact.html">
                        Contact
                    </a>
                </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
      </div>
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <span class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" data-toggle="tooltip">
    <a class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="fa-regular fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></a>
</span>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          <a href="https://github.com/opendp" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-toggle="tooltip"><span><i class="fa-brands fa-square-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          <a href="https://twitter.com/opendp_org" title="Twitter" class="nav-link" rel="noopener" target="_blank" data-toggle="tooltip"><span><i class="fa-brands fa-square-twitter"></i></span>
            <label class="sr-only">Twitter</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          <a href="https://github.com/opendp/opendp/discussions" title="GitHub Discussions" class="nav-link" rel="noopener" target="_blank" data-toggle="tooltip"><span><i class="far fa-comments"></i></span>
            <label class="sr-only">GitHub Discussions</label></a>
        </li>
      </ul>
      </div>
      
    </div>
    
  </div>

  
  <div class="sidebar-start-items sidebar-primary__section">
    <div class="sidebar-start-items__item">
<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
    <div class="sidebar-start-items__item"><nav class="bd-links" id="bd-docs-nav" aria-label="Section navigation">
  <p class="bd-links__title" role="heading" aria-level="1">
    Section Navigation
  </p>
  <div class="bd-toc-item navbar-nav">
    <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../limitations.html">Limitations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting-started.html">Getting Started</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">Programming Framework</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="core-structures.html">Core Structures</a></li>
<li class="toctree-l2"><a class="reference internal" href="supporting-elements.html">Supporting Elements</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">A Framework to Understand DP</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../constructors/index.html">Constructors</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../constructors/transformations.html">Transformations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../constructors/measurements.html">Measurements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../constructors/combinators.html">Combinators</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../utilities/index.html">Utilities</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../utilities/typing.html">Typing</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../utilities/accuracy/index.html">Accuracy</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../utilities/accuracy/accuracy-pitfalls.html">Accuracy: Pitfalls and Edge Cases</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../utilities/parameter-search.html">Parameter Search</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../putting-it-together.html">Putting It Together</a></li>
</ul>

  </div>
</nav>
    </div>
    <div class="sidebar-start-items__item">
<h6>Branches</h6>
<ul>
    <li><a href="a-framework-to-understand-dp.html" style="font-weight: bold">latest</a></li>
    <li><a href="../../../stable/index.html" style="font-weight: normal">stable</a></li>
</ul>


<h6 id="releases_header">Releases
    <div id="releases_symbol" style="float:right"></div>
</h6>
<ul id="releases_content">
    <li><a href="../../../v0.5.0/index.html" style="font-weight: normal">v0.5.0</a></li>
    <li><a href="../../../v0.5.0-rc.1/index.html" style="font-weight: normal">v0.5.0-rc.1</a></li>
    <li><a href="../../../v0.4.0/index.html" style="font-weight: normal">v0.4.0</a></li>
    <li><a href="../../../v0.3.0/index.html" style="font-weight: normal">v0.3.0</a></li>
    <li><a href="../../../v0.2.4/index.html" style="font-weight: normal">v0.2.4</a></li>
    <li><a href="../../../v0.2.3/index.html" style="font-weight: normal">v0.2.3</a></li>
    <li><a href="../../../v0.2.2/index.html" style="font-weight: normal">v0.2.2</a></li>
    <li><a href="../../../v0.2.1/index.html" style="font-weight: normal">v0.2.1</a></li>
    <li><a href="../../../v0.2.0/index.html" style="font-weight: normal">v0.2.0</a></li>
    <li><a href="../../../v0.1.0/index.html" style="font-weight: normal">v0.1.0</a></li>
</ul>
<script>
    let expanded = !!JSON.parse(localStorage.getItem('expanded'));

    let releasesHeader = document.getElementById("releases_header");
    let releasesSymbol = document.getElementById("releases_symbol");
    let releasesContent = document.getElementById("releases_content");

    function setReleasesState() {
        localStorage.setItem("expanded", JSON.stringify(expanded))
        releasesContent.style.display = expanded ? "block" : "none";
        releasesSymbol.classList.add(expanded ? 'minus' : 'plus')
        releasesSymbol.classList.remove(expanded ? 'plus' : 'minus')
    }

    setReleasesState()
    releasesHeader.addEventListener("click", function() {
        expanded = !expanded;
        setReleasesState()
    })
</script>
<style>
    .plus {
        position: relative;
        width:20px;
        height:20px;
        background:#676767;
    }

    .plus:before,
    .plus:after {
        content: "";
        position:absolute;
        background:#fff;
    }

    .plus:before {
        left:50%;
        top:4px;
        bottom:4px;
        width:3px;
        transform:translateX(-50%);
    }

    .plus:after {
        top:50%;
        left:4px;
        right:4px;
        height:3px;
        transform:translateY(-50%);
    }



    .minus {
        position: relative;
        width:20px;
        height:20px;
        background:#676767;
    }

    .minus:before,
    .minus:after {
        content: "";
        position:absolute;
        background:#fff;
    }

    .minus:after {
        top:50%;
        left:4px;
        right:4px;
        height:3px;
        transform:translateY(-50%);
    }
</style>

    </div>
  </div>
  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

      </div>
      <main class="bd-main">
        
        
        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                
            </div>
            
            
            <article class="bd-article" role="main">
              
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="admonition note">
  This page was generated from
  <a class="reference external" href="https://github.com/opendp/opendp/tree/main/docs/source/user/programming-framework/a-framework-to-understand-dp.ipynb" target="_blank">docs/source/user/programming-framework/a-framework-to-understand-dp.ipynb</a>.
  Interactive online version:
  <span style="white-space: nowrap;"><a href="https://mybinder.org/v2/gh/opendp/opendp/main?filepath=docs/source/user/programming-framework/a-framework-to-understand-dp.ipynb" target="_blank"><img alt="Binder badge" src="https://mybinder.org/badge_logo.svg" style="vertical-align:text-bottom"></a>.</span>
</div><section id="A-Framework-to-Understand-DP">
<h1>A Framework to Understand DP<a class="headerlink" href="#A-Framework-to-Understand-DP" title="Permalink to this heading">#</a></h1>
<p>This resource introduces differential privacy from the perspective of the OpenDP programming framework. No prior knowledge is assumed of differential privacy (DP), but you will likely still find this resource useful if you already have a background in DP. Prior knowledge in basic probability, like random variables, will be useful.</p>
<p>Assume we have a vector dataset <span class="math notranslate nohighlight">\(u\)</span> where each record contains sensitive information about a different individual.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># u is a small vector dataset with contributions from:</span>
<span class="c1">#   [Alice, Jane, John, Jack, ...]</span>
<span class="n">u</span> <span class="o">=</span> <span class="p">[</span><span class="mi">12</span><span class="p">,</span>    <span class="mi">10</span><span class="p">,</span>   <span class="mi">8</span><span class="p">,</span>    <span class="mi">7</span><span class="p">,</span>       <span class="p">]</span>
</pre></div>
</div>
</div>
<p>We can use differential privacy to collect measurements (statistics such as means and histograms) on this dataset, without revealing information about specific individuals.</p>
<div class="line-block">
<div class="line">To understand DP, it is important to first understand:</div>
<div class="line">1. distance between datasets</div>
<div class="line">2. distance between distributions</div>
</div>
<section id="Distance-Between-Datasets---Adjacency">
<h2>Distance Between Datasets - Adjacency<a class="headerlink" href="#Distance-Between-Datasets---Adjacency" title="Permalink to this heading">#</a></h2>
<p>An adjacent dataset is any dataset that differs from our dataset by a single individual. Returning to our vector dataset example, assume our dataset <span class="math notranslate nohighlight">\(u\)</span> has one record that contains information about a person, Alice. Then one adjacent dataset <span class="math notranslate nohighlight">\(v\)</span> would contain every row in <span class="math notranslate nohighlight">\(u\)</span> except for the row with Alice’s information.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># v is one (of many) datasets that are adjacent to u</span>
<span class="c1">#   [Jane, John, Jack, ...] (without Alice!)</span>
<span class="n">v</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span>   <span class="mi">8</span><span class="p">,</span>    <span class="mi">7</span><span class="p">,</span>       <span class="p">]</span>
</pre></div>
</div>
</div>
<p>You can construct other datasets adjacent to <span class="math notranslate nohighlight">\(u\)</span> by dropping a different row or adding a new row. When one person may contribute up to <span class="math notranslate nohighlight">\(k\)</span> rows, adjacent datasets differ by up to <span class="math notranslate nohighlight">\(k\)</span> additions and removals.</p>
<p>The number of additions/removals between any two datasets is equivalent to the cardinality of the symmetric difference between the multisets <span class="math notranslate nohighlight">\(u\)</span> and <span class="math notranslate nohighlight">\(v\)</span>. We call this metric the symmetric distance.</p>
<div class="math notranslate nohighlight">
\[d_{Sym}(u, v) = |u \triangle v|\]</div>
<p>And in code:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">d_Sym</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;symmetric distance between multisets u and v&quot;&quot;&quot;</span>
    <span class="c1"># NOT this, as sets are not multisets. Loses multiplicity:</span>
    <span class="c1"># return len(set(u).symmetric_difference(set(v)))</span>

    <span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
    <span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">u</span><span class="p">),</span> <span class="n">Counter</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="c1"># indirectly compute symmetric difference via the union of asymmetric differences</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">(((</span><span class="n">u</span> <span class="o">-</span> <span class="n">v</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">v</span> <span class="o">-</span> <span class="n">u</span><span class="p">))</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>


<span class="c1"># compute the symmetric distance between our two example datasets:</span>
<span class="n">d_Sym</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1
</pre></div></div>
</div>
<p><span class="math notranslate nohighlight">\(d_{Sym}(\{12, 10, 8, 7\}, \{10, 8, 7\}) = |\{12, 10, 8, 7\} \triangle \{10, 8, 7\}| = |\{12\}| = 1\)</span></p>
<p>In practice, we never directly compute these distances. In order to apply differentially private methods, you need to establish an upper bound on the distance between adjacent datasets. Equivalently, this is an upper bound on the number of records any one individual may contribute.</p>
<p>For instance, in the vector dataset example, it was stipulated that each element contains sensitive information about a different individual. This statement implies that the symmetric distance between adjacent datasets, where one individual is added or removed, is at most one. That is, for any choice of datasets <span class="math notranslate nohighlight">\(u\)</span> and <span class="math notranslate nohighlight">\(v\)</span> such that <span class="math notranslate nohighlight">\(u\)</span> is adjacent to <span class="math notranslate nohighlight">\(v\)</span> (denoted <span class="math notranslate nohighlight">\(u \sim_{Sym} v\)</span>), we have that <span class="math notranslate nohighlight">\(d_{Sym}(u, v) \leq 1\)</span>.</p>
<p>Before moving on, there are some trivial generalizations. A dataset need not be a vector, it could be a dataframe or any other collection with a concept of records. There are also other dataset metrics aside from <code class="docutils literal notranslate"><span class="pre">SymmetricDistance</span></code> (used for unbounded DP), such as <code class="docutils literal notranslate"><span class="pre">ChangeOneDistance</span></code> (used for bounded DP). There are also variations of metrics that are sensitive to data ordering, metrics for describing distances between graphs, and more!</p>
<p>You should now have a sense for what an adjacent dataset means, how dataset distances work, and an intuitive understanding of the symmetric distance metric.</p>
</section>
<section id="Distance-Between-Distributions---Divergence">
<h2>Distance Between Distributions - Divergence<a class="headerlink" href="#Distance-Between-Distributions---Divergence" title="Permalink to this heading">#</a></h2>
<p>You can think of a measurement <span class="math notranslate nohighlight">\(M(\cdot)\)</span> as a differentially private statistic. Measurements are random variables (RVs), that is, they sample from noise distributions. The outputs of a measurement are realizations of a random variable that follow a known probability distribution. Measurements only have one parameter: a dataset (for context, a Laplace RV has parameters for shift and scale). This section describes how to measure distance between the distributions of measurements on adjacent
datasets.</p>
<p>A common measurement is the Laplace DP sum, which is a sample from the Laplace distribution centered at the dataset sum with a fixed noise scale. The following plot compares the distribution of the DP sum on dataset <span class="math notranslate nohighlight">\(u\)</span> with the distribution of the DP sum on dataset <span class="math notranslate nohighlight">\(v\)</span>, when the noise scale is fixed to <code class="docutils literal notranslate"><span class="pre">25</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">laplace</span>

<span class="n">scale</span> <span class="o">=</span> <span class="mi">25</span>

<span class="c1"># while in this case the output domain includes all reals, we only bother plotting part of it</span>
<span class="n">output_domain</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">-</span> <span class="n">scale</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="n">u</span><span class="p">)</span> <span class="o">+</span> <span class="n">scale</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">rv_M</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;returns a random variable, M(x)&quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">laplace</span>
    <span class="k">return</span> <span class="n">laplace</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plot_pdfs</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">output_domain</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">output_domain</span><span class="p">,</span> <span class="n">rv_M</span><span class="p">(</span><span class="n">u</span><span class="p">)</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">output_domain</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;$p_{M(u)}(x)$&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">output_domain</span><span class="p">,</span> <span class="n">rv_M</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">output_domain</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;$p_{M(v)}(x)$&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;density: $p_</span><span class="si">{RV}</span><span class="s1">(x)$&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;output_domain: x&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">prop</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;size&#39;</span><span class="p">:</span> <span class="mi">15</span><span class="p">})</span>
<span class="n">plot_pdfs</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">output_domain</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/user_programming-framework_a-framework-to-understand-dp_9_0.png" src="../../_images/user_programming-framework_a-framework-to-understand-dp_9_0.png" />
</div>
</div>
<p>We are interested in the greatest divergence, a measure of the dissimilarity of these two distributions. While divergences are not necessarily distances, we informally refer to them as distances. A common measure of divergence is based on the log ratio of probabilities:</p>
<div class="math notranslate nohighlight">
\[d_{MaxDivergence}(M(u), M(v)) = \max\limits_{S \subseteq DO: Pr[M(v) \in S] &gt; 0} log\left(\frac{Pr[M(u) \in S]}{Pr[M(v) \in S]}\right)\]</div>
<p>In this equation we define the distance between the RVs of <span class="math notranslate nohighlight">\(M(u)\)</span> and <span class="math notranslate nohighlight">\(M(v)\)</span> to be the maximum divergence among all possible subsets of the output domain with nonzero probability.</p>
<p>For our DP sum with Laplacian noise example, the output domain of <span class="math notranslate nohighlight">\(M(\cdot)\)</span> is the set of all real numbers, <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>. In the plot below, I illustrate this equation for one randomly chosen subset <span class="math notranslate nohighlight">\(S\)</span> of the output domain:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_S</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">S</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;draw the probability regions spanned by S&quot;&quot;&quot;</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">rv_M</span><span class="p">(</span><span class="n">u</span><span class="p">)</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">S</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;$Pr[M(u) \in S]$&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.4</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">rv_M</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">S</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;$Pr[M(v) \in S]$&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.4</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">S</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">S</span><span class="p">)],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;S&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="c1"># re-run this notebook to see different choices of S</span>
<span class="n">S</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">*</span><span class="nb">sorted</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">output_domain</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)))</span>

<span class="n">plot_pdfs</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">output_domain</span><span class="p">)</span>
<span class="n">plot_S</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">S</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/user_programming-framework_a-framework-to-understand-dp_11_0.png" src="../../_images/user_programming-framework_a-framework-to-understand-dp_11_0.png" />
</div>
</div>
<p>The area of the blue region is the probability that <span class="math notranslate nohighlight">\(M(u)\)</span> is in <span class="math notranslate nohighlight">\(S\)</span>… and similarly the area of the orange region is <span class="math notranslate nohighlight">\(Pr[M(v) \in S]\)</span>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">divergence_over_S</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">S</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;prints the Divergence(M(u), M(v)) over some interval S, assuming M(x) = Laplace(sum(x), scale)&quot;&quot;&quot;</span>

    <span class="c1"># integrate over both regions</span>
    <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">S</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">S</span><span class="p">)</span>
    <span class="n">pr_Mu_in_S</span> <span class="o">=</span> <span class="n">rv_M</span><span class="p">(</span><span class="n">u</span><span class="p">)</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">upper</span><span class="p">)</span> <span class="o">-</span> <span class="n">rv_M</span><span class="p">(</span><span class="n">u</span><span class="p">)</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">lower</span><span class="p">)</span> <span class="c1"># blue</span>
    <span class="n">pr_Mv_in_S</span> <span class="o">=</span> <span class="n">rv_M</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">upper</span><span class="p">)</span> <span class="o">-</span> <span class="n">rv_M</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">lower</span><span class="p">)</span> <span class="c1"># orange</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;area of blue region:  &quot;</span><span class="p">,</span> <span class="n">pr_Mu_in_S</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;area of orange region:&quot;</span><span class="p">,</span> <span class="n">pr_Mv_in_S</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;divergence for this S:&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">pr_Mu_in_S</span> <span class="o">/</span> <span class="n">pr_Mv_in_S</span><span class="p">)))</span>
<span class="n">divergence_over_S</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">S</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
area of blue region:   0.29260854415920934
area of orange region: 0.18106130742629256
divergence for this S: 0.47999999999999965
</pre></div></div>
</div>
<p>This shows the divergence between the RVs of <span class="math notranslate nohighlight">\(M(u)\)</span> and <span class="math notranslate nohighlight">\(M(v)\)</span> for one choice of S, but keep in mind that <span class="math notranslate nohighlight">\(d_{MaxDivergence}(M(u), M(v))\)</span> is the greatest divergence over any choice of <span class="math notranslate nohighlight">\(S\)</span>. Intuitively, the divergence between the RVs of <span class="math notranslate nohighlight">\(M(u)\)</span> and <span class="math notranslate nohighlight">\(M(v)\)</span> for the same <span class="math notranslate nohighlight">\(S\)</span> increases if Alice made a greater contribution to the statistic:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># hypothetical: what if Alice&#39;s contribution was 100, instead of 12?</span>
<span class="n">u_prime</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="o">*</span><span class="n">u</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>
<span class="n">divergence_over_S</span><span class="p">(</span><span class="n">u_prime</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">S</span><span class="p">)</span>

<span class="n">output_domain</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">-</span> <span class="n">scale</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="n">u_prime</span><span class="p">)</span> <span class="o">+</span> <span class="n">scale</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plot_pdfs</span><span class="p">(</span><span class="n">u_prime</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">output_domain</span><span class="p">)</span>
<span class="n">plot_S</span><span class="p">(</span><span class="n">u_prime</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">S</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
area of blue region:   0.020880917194247027
area of orange region: 0.18106130742629256
divergence for this S: 2.1600000000000006
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/user_programming-framework_a-framework-to-understand-dp_15_1.png" src="../../_images/user_programming-framework_a-framework-to-understand-dp_15_1.png" />
</div>
</div>
<p>As we can see, when the divergence between probability distributions is greater, we can more confidently distinguish which distribution a sample came from. This motivates why we use the statistical divergence as a measure of privacy.</p>
<p>In practice, it isn’t feasible to compute the divergence for all possible choices of <span class="math notranslate nohighlight">\(S\)</span>. Fortunately, we won’t need to directly compute this anyways.</p>
</section>
<section id="Definition-of-Privacy">
<h2>Definition of Privacy<a class="headerlink" href="#Definition-of-Privacy" title="Permalink to this heading">#</a></h2>
<p>Now that we have an understanding of distances between datasets, and distances between distributions, we can define the privacy of a measurement, <span class="math notranslate nohighlight">\(M(\cdot)\)</span>:</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(M(\cdot)\)</span> is <span class="math notranslate nohighlight">\(\epsilon\)</span>-differentially private if, for any choice of datasets <span class="math notranslate nohighlight">\(u\)</span> and <span class="math notranslate nohighlight">\(v\)</span> such that <span class="math notranslate nohighlight">\(d_{Sym}(u, v) \leq k\)</span>, we have that <span class="math notranslate nohighlight">\(d_{MaxDivergence}(M(u), M(v)) \leq \epsilon\)</span>.</p>
</div></blockquote>
<p>In this definition, we relate a dataset distance <span class="math notranslate nohighlight">\(k\)</span> to another distance <span class="math notranslate nohighlight">\(\epsilon\)</span>. This <span class="math notranslate nohighlight">\(\epsilon\)</span> is more general than the max divergence we computed in the previous section because it is the greatest divergence over all possible choices of <span class="math notranslate nohighlight">\(S\)</span>, <em>and over all possible pairs of adjacent datasets</em> <span class="math notranslate nohighlight">\(u\)</span> and <span class="math notranslate nohighlight">\(v\)</span>.</p>
<p>This has a very practical interpretation: Let’s say I have a dataset <span class="math notranslate nohighlight">\(x\)</span> for which an individual user can contribute at most <span class="math notranslate nohighlight">\(k\)</span> rows, and a statistic <span class="math notranslate nohighlight">\(M(\cdot)\)</span> that is <span class="math notranslate nohighlight">\(\epsilon\)</span>-DP when user contribution is at most <span class="math notranslate nohighlight">\(k\)</span>. By the DP guarantee, it is proven that the influence of any one individual on the data release induces a divergence no greater than <span class="math notranslate nohighlight">\(\epsilon\)</span>. Thus, assuming a reasonably small choice of <span class="math notranslate nohighlight">\(\epsilon\)</span>, the individual’s participation in
the statistical release is private, because their influence on the data release is at most <span class="math notranslate nohighlight">\(\epsilon\)</span>-distinguishable.</p>
<p>If you have some background in differential privacy you may be more familiar with a definition of privacy worded like this:</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(M(\cdot)\)</span> is <span class="math notranslate nohighlight">\(\epsilon\)</span>-differentially private if, for any choice of adjacent datasets <span class="math notranslate nohighlight">\(u\)</span> and <span class="math notranslate nohighlight">\(v\)</span>, we have that <span class="math notranslate nohighlight">\(Pr[M(u) \in S] \leq e^\epsilon Pr[M(v) \in S]\)</span>.</p>
</div></blockquote>
<p>This is mostly equivalent, because of the way we’ve defined <span class="math notranslate nohighlight">\(d_{MaxDivergence}(M(u), M(v))\)</span> in the previous section. However, this formulation of the definition is ambiguous about what makes a dataset adjacent. To obtain well-defined privacy guarantees, it is important to specify the dataset metric and dataset distance.</p>
<p>We further generalize the definition of privacy:</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(M(\cdot)\)</span> is <span class="math notranslate nohighlight">\(d_{out}\)</span>-differentially private with respect to input metric <span class="math notranslate nohighlight">\(MI\)</span> and output measure <span class="math notranslate nohighlight">\(MO\)</span> if, for any choice of datasets <span class="math notranslate nohighlight">\(u\)</span> and <span class="math notranslate nohighlight">\(v\)</span> such that <span class="math notranslate nohighlight">\(d_{MI}(u, v) \leq d_{in}\)</span>, we have that <span class="math notranslate nohighlight">\(d_{MO}(M(u), M(v)) \leq d_{out}\)</span>.</p>
</div></blockquote>
<p>The first definition can be reclaimed by letting <span class="math notranslate nohighlight">\(MI\)</span> be <code class="docutils literal notranslate"><span class="pre">SymmetricDistance</span></code> and <span class="math notranslate nohighlight">\(MO\)</span> be <code class="docutils literal notranslate"><span class="pre">MaxDivergence</span></code>. <span class="math notranslate nohighlight">\(MO\)</span> can be set to other measures of divergence to represent approximate (<span class="math notranslate nohighlight">\(\epsilon, \delta\)</span>)-differential privacy, or zero-concentrated <span class="math notranslate nohighlight">\(\rho\)</span>-differential privacy. Similarly, our choice of <code class="docutils literal notranslate"><span class="pre">SymmetricDistance</span></code> represents unbounded DP, but we can represent bounded DP by letting <span class="math notranslate nohighlight">\(MI\)</span> be <code class="docutils literal notranslate"><span class="pre">ChangeOneDistance</span></code>.</p>
</section>
<section id="Distance-Between-Aggregates---Sensitivity">
<h2>Distance Between Aggregates - Sensitivity<a class="headerlink" href="#Distance-Between-Aggregates---Sensitivity" title="Permalink to this heading">#</a></h2>
<p>The <em>sensitivity</em> is the greatest amount an aggregate can change when computed on an adjacent dataset. Aggregators are deterministic statistics (like the sum or histogram functions), and their exact outputs are aggregates. More generally, a transformation <span class="math notranslate nohighlight">\(T(\cdot)\)</span> is a deterministic function from a dataset to a dataset. Aggregators are a kind of transformation, and aggregates are a kind of dataset.</p>
<p>One example of a sensitivity metric is the <code class="docutils literal notranslate"><span class="pre">AbsoluteDistance</span></code>, which is used to measure the distance between scalar aggregates.</p>
<div class="math notranslate nohighlight">
\[d_{Abs}(a, b) = |a - b|\]</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">d_Abs</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;absolute distance between a and b&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">abs</span><span class="p">(</span><span class="n">a</span> <span class="o">-</span> <span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>We can use the absolute distance metric to express the sensitivity of the sum aggregator. In our vector dataset example, we know each individual can contribute at most one record. Since this record is unbounded, it can perturb the sum an arbitrarily large amount towards positive or negative infinity. This is unfortunate, because it implies that the divergence is also infinite!</p>
<p>In order to attain a finite sensitivity, it is customary to clamp— that is, to replace any value less than a lower bound with the lower bound, and any value greater than an upper bound with the upper bound.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">clamped_sum_0_12</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;a naive function that computes the sum, where each element is clamped within [0, 12]&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
</pre></div>
</div>
</div>
<p>Broadly speaking, if the transformation clamps data to the interval <span class="math notranslate nohighlight">\([L, U]\)</span>, and we know each individual contributes at most <span class="math notranslate nohighlight">\(d_{in}\)</span> records, then the clamped sum sensitivity (<span class="math notranslate nohighlight">\(d_{out}\)</span>) is</p>
<div class="math notranslate nohighlight">
\[max_{u \sim_{Sym} v} |clamped\_sum(u) - clamped\_sum(v)| = d_{in} \cdot max(|L|, U)\]</div>
<p>We can use this to solve for the sensitivity of <span class="math notranslate nohighlight">\(clamped\_sum\_0\_12\)</span>, by letting <span class="math notranslate nohighlight">\([L, U] = [0, 12]\)</span>. Thus its sensitivity is <span class="math notranslate nohighlight">\(1 \cdot max(|0|, 12) = 12\)</span>. For any conceivable dataset <span class="math notranslate nohighlight">\(u\)</span>, adding or removing any individual (to get some dataset <span class="math notranslate nohighlight">\(v\)</span>) can change the sum by at most <span class="math notranslate nohighlight">\(12\)</span>.</p>
<p>Our current choice of <span class="math notranslate nohighlight">\(u\)</span> and <span class="math notranslate nohighlight">\(v\)</span> is an example that maximizes the absolute distance:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">d_Abs</span><span class="p">(</span><span class="n">clamped_sum_0_12</span><span class="p">(</span><span class="n">u</span><span class="p">),</span> <span class="n">clamped_sum_0_12</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
12
</pre></div></div>
</div>
<p>You can even use the <code class="docutils literal notranslate"><span class="pre">AbsoluteDistance</span></code> as the input metric <span class="math notranslate nohighlight">\(MI\)</span> of a measurement <span class="math notranslate nohighlight">\(M(\cdot)\)</span> (see the definition of privacy). Let’s define a new function <span class="math notranslate nohighlight">\(laplace\_noise\)</span> to illustrate this:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">laplace_noise</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;a naive function that adds an approximation to Laplace noise&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">laplace</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>We let <span class="math notranslate nohighlight">\(MI\)</span> be <code class="docutils literal notranslate"><span class="pre">AbsoluteDistance</span></code> and <span class="math notranslate nohighlight">\(MO\)</span> be <code class="docutils literal notranslate"><span class="pre">MaxDivergence</span></code>. It can be shown that for any choice of <span class="math notranslate nohighlight">\(u\)</span> and <span class="math notranslate nohighlight">\(v\)</span> such that <span class="math notranslate nohighlight">\(d_{Sym}(u, v) \leq d_{in}\)</span>, and <span class="math notranslate nohighlight">\(d_{out} = d_{in} / scale\)</span>, then:</p>
<div class="math notranslate nohighlight">
\[d_{MaxDivergence}(u, v) \leq d_{out}\]</div>
<p>Therefore, if the data types in this function had infinite precision, then <span class="math notranslate nohighlight">\(laplace\_noise\)</span> would be a measurement. Other common metrics to express sensitivities are <code class="docutils literal notranslate"><span class="pre">L1Distance</span></code> and <code class="docutils literal notranslate"><span class="pre">L2Distance</span></code>.</p>
</section>
<section id="Definition-of-Stability">
<h2>Definition of Stability<a class="headerlink" href="#Definition-of-Stability" title="Permalink to this heading">#</a></h2>
<p>Similar to how we defined the privacy of a measurement <span class="math notranslate nohighlight">\(M(\cdot)\)</span>, we can also define the stability of a transformation, <span class="math notranslate nohighlight">\(T(\cdot)\)</span>:</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(T(\cdot)\)</span> is <span class="math notranslate nohighlight">\(d_{out}\)</span>-stable with respect to input metric <span class="math notranslate nohighlight">\(MI\)</span> and output metric <span class="math notranslate nohighlight">\(MO\)</span> if, for any choice of datasets <span class="math notranslate nohighlight">\(u\)</span> and <span class="math notranslate nohighlight">\(v\)</span> such that <span class="math notranslate nohighlight">\(d_{MI}(u, v) \leq d_{in}\)</span>, we have that <span class="math notranslate nohighlight">\(d_{MO}(T(u), T(v)) \leq d_{out}\)</span>.</p>
</div></blockquote>
<p>An example is the <span class="math notranslate nohighlight">\(clamped\_sum\_0\_12\)</span> function from the previous section. If the data types in <span class="math notranslate nohighlight">\(clamped\_sum\_0\_12\)</span> had infinite precision, it would be a stable transformation where <span class="math notranslate nohighlight">\(MI\)</span> is <code class="docutils literal notranslate"><span class="pre">SymmetricDistance</span></code> and <span class="math notranslate nohighlight">\(MO\)</span> is <code class="docutils literal notranslate"><span class="pre">AbsoluteDistance</span></code>. We’ve previously shown that when <span class="math notranslate nohighlight">\(d_{in} = 1\)</span>, the sensitivity <span class="math notranslate nohighlight">\(d_{out} = 12\)</span>.</p>
<p>This stability guarantee does not carry privacy implications, but it lets us construct building blocks that can be chained together. If the output metric <span class="math notranslate nohighlight">\(MO\)</span> and output domain <span class="math notranslate nohighlight">\(DO\)</span> of a transformation <span class="math notranslate nohighlight">\(T(\cdot)\)</span> conform with the input metric <span class="math notranslate nohighlight">\(MI\)</span> and input domain <span class="math notranslate nohighlight">\(DI\)</span> of a measurement <span class="math notranslate nohighlight">\(M(\cdot)\)</span>, then it is valid to construct a new measurement <span class="math notranslate nohighlight">\(M_{chained}(\cdot) = M(T(\cdot))\)</span>. We can similarly construct a new transformation
<span class="math notranslate nohighlight">\(T_{chained}(\cdot) = T_2(T_1(\cdot))\)</span>.</p>
<p>Notice that the output domain and metric of the <span class="math notranslate nohighlight">\(clamped\_sum\_0\_12\)</span> transformation conform with the input metric and domain of the <span class="math notranslate nohighlight">\(laplace\_noise\)</span> measurement, so we can chain these together:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">laplace_sum</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;a naive function that computes the noisy clamped sum&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">laplace_noise</span><span class="p">(</span><span class="n">clamped_sum_0_12</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<p>Since this function was constructed by chaining a stable transformation and private measurement, it is trivial to prove that it is a private measurement (if the data types had infinite precision). The new chained measurement’s <span class="math notranslate nohighlight">\(MI\)</span> is <code class="docutils literal notranslate"><span class="pre">SymmetricDistance</span></code>, and <span class="math notranslate nohighlight">\(MO\)</span> is <code class="docutils literal notranslate"><span class="pre">MaxDivergence</span></code>, and when the dataset distance <span class="math notranslate nohighlight">\(d_{in} = 1\)</span>, we have that <span class="math notranslate nohighlight">\(\epsilon = d_{out} = d_{in} \cdot max(|0|, 12) / 25 = d_{in} \cdot 0.48 = 0.48\)</span>. That is, when an individual can contribute at
most one record, the maximum observable divergence among the output distributions is <span class="math notranslate nohighlight">\(0.48\)</span>.</p>
</section>
<section id="Stability-Maps-and-Privacy-Maps">
<h2>Stability Maps and Privacy Maps<a class="headerlink" href="#Stability-Maps-and-Privacy-Maps" title="Permalink to this heading">#</a></h2>
<p>A crucial takeaway from this notebook is a high-level understanding that <em>differential privacy is a system to relate distances</em> (<span class="math notranslate nohighlight">\(d_{in}\)</span> and <span class="math notranslate nohighlight">\(d_{out}\)</span>). If you can establish a bound on the distance to adjacent datasets <span class="math notranslate nohighlight">\(d_{in}\)</span> (in terms of some metric <span class="math notranslate nohighlight">\(MI\)</span>) then you can work out the stability or privacy properties <span class="math notranslate nohighlight">\(d_{out}\)</span> (in terms of some metric or measure <span class="math notranslate nohighlight">\(MO\)</span>) of computations made on your data.</p>
<p>We encapsulate this relationship between distances with one last abstraction, a map. A map is a function, associated with your computation, that computes the smallest <span class="math notranslate nohighlight">\(d_{out}\)</span> for any given <span class="math notranslate nohighlight">\(d_{in}\)</span>. A computation is <span class="math notranslate nohighlight">\(d_{out}\)</span>-DP when inputs are <span class="math notranslate nohighlight">\(d_{in}\)</span>-adjacent, or equivalently <span class="math notranslate nohighlight">\((d_{in}, d_{out})\)</span>-close, so long as <span class="math notranslate nohighlight">\(map(d_{in}) \leq d_{out}\)</span>.</p>
<p>The stability map for the <span class="math notranslate nohighlight">\(clamped\_sum\_0\_12\)</span> function is as follows:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">clamped_sum_0_12_map</span><span class="p">(</span><span class="n">d_in</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">d_in</span> <span class="o">*</span> <span class="nb">max</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">12</span><span class="p">)</span>

<span class="c1"># find the smallest d_out (absolute distance) of clamped_sum_0_12 when d_in (symmetric distance) is 1</span>
<span class="n">clamped_sum_0_12_map</span><span class="p">(</span><span class="n">d_in</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
12
</pre></div></div>
</div>
<p>This map is just a repackaging of our previous formula for the clamped sum sensitivity, so that <span class="math notranslate nohighlight">\(d_{in}\)</span> can be set later. It is referred to as a <em>stability</em> map because the output distance is in terms of a stability metric.</p>
<p>The same pattern holds for the privacy map of the <span class="math notranslate nohighlight">\(laplace\_noise\)</span> measurement:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">laplace_noise_map</span><span class="p">(</span><span class="n">d_in</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">d_in</span> <span class="o">/</span> <span class="n">scale</span>

<span class="c1"># find the smallest d_out (epsilon) of laplace_noise when d_in (absolute distance) is 12</span>
<span class="n">laplace_noise_map</span><span class="p">(</span><span class="n">d_in</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.48
</pre></div></div>
</div>
<p>This time we refer to it as a privacy map, because the output distance is in terms of a privacy measure, instead of a stability metric. Now that we have the stability map for the clamped sum transformation and the privacy map for the Laplace noise measurement, we can automatically construct the privacy map for the Laplace sum measurement:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">laplace_sum_map</span><span class="p">(</span><span class="n">d_in</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">laplace_noise_map</span><span class="p">(</span><span class="n">clamped_sum_0_12_map</span><span class="p">(</span><span class="n">d_in</span><span class="p">))</span>

<span class="c1"># find the smallest d_out (epsilon) of laplace_noise when d_in (symmetric distance) is 1</span>
<span class="n">laplace_sum_map</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.48
</pre></div></div>
</div>
<p>We’ve now come full-circle. In the “Distance Between Distributions” section, we computed an example divergence for one choice of <span class="math notranslate nohighlight">\(S\)</span>. We have now indirectly computed an upper bound for that divergence of <span class="math notranslate nohighlight">\(0.48\)</span>. You may notice that some choices of <span class="math notranslate nohighlight">\(S\)</span> in that section can give divergences very slightly larger than <span class="math notranslate nohighlight">\(0.48\)</span>. This is because floating-point numbers have finite precision, so intermediate computations were subject to rounding that introduced error.</p>
<p>The transformation and measurement examples in this notebook are only <span class="math notranslate nohighlight">\((d_{in}, d_{out})\)</span>-close if we assume the data types have infinite precision— and they don’t! Building transformations or measurements that have proven stability or privacy properties is nontrivial, especially if you account for finite precision in data types. This is the purpose of the OpenDP library: to help you build robust transformations and measurements with rigorous privacy properties.</p>
</section>
</section>


            </article>
            
            
            
            <footer class="bd-footer-article">
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="supporting-elements.html" title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">Supporting Elements</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="../constructors/index.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">Constructors</p>
  </div>
  <i class="fa-solid fa-angle-right"></i>
  </a>
</div>
            </footer>
            
          </div>
          
          
          
            <div class="bd-sidebar-secondary bd-toc">
              
<div class="toc-item">
  
<div class="tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
</div>
<nav id="bd-toc-nav" class="page-toc">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Distance-Between-Datasets---Adjacency">
   Distance Between Datasets - Adjacency
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Distance-Between-Distributions---Divergence">
   Distance Between Distributions - Divergence
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Definition-of-Privacy">
   Definition of Privacy
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Distance-Between-Aggregates---Sensitivity">
   Distance Between Aggregates - Sensitivity
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Definition-of-Stability">
   Definition of Stability
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Stability-Maps-and-Privacy-Maps">
   Stability Maps and Privacy Maps
  </a>
 </li>
</ul>

</nav>
</div>

<div class="toc-item">
  
<div id="searchbox"></div>
</div>

<div class="toc-item">
  
</div>

<div class="toc-item">
  
<div class="tocsection sourcelink">
    <a href="../../_sources/user/programming-framework/a-framework-to-understand-dp.ipynb.txt">
        <i class="fa-solid fa-file-lines"></i> Show Source
    </a>
</div>

</div>

            </div>
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
          </div>
        </footer>
        
      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1e1de1a1873e13ef5536"></script>

  <footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    
<p class="copyright">

    &copy; Copyright 2022.<br>

</p>

  </div>
  
  <div class="footer-item">
    
<p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.1.1.<br>
</p>

  </div>
  
</div>
  </footer>
  </body>
</html>